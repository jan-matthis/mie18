{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To step through this notebook, you will need to install a number of packages. First off all, we will need PyTorch, please follow the installation instructions provided at http://pytorch.org/.\n",
    "\n",
    "After successfully doing so, install the following additional packages:\n",
    "- `visdom` : package for visualisations\n",
    "- `tqdm` : package to display progress bars\n",
    "\n",
    "(Use `conda` or `pip` / `pip3` depending on your local setup.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can skip execution of the next cell. \n",
    "\n",
    "(Executing the next cell enables presentation mode (navigate with arrow keys in cell mode); to get out of presentation mode, clear all cell output -- the menu becomes visible on hover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" href=\"css/jupyter.css\">\n",
    "<link rel=\"stylesheet\" href=\"css/presenter.css\">\n",
    "<link rel=\"stylesheet\" href=\"css/cells.css\">\n",
    "<link rel=\"stylesheet\" href=\"css/codemirror.css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# progress bars\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# in case GPUs are used, limit to single device\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor  # Uncomment this to run on GPU\n",
    "\n",
    "# matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "fig_size = (7, 7)\n",
    "plt.rcParams['axes.spines.left'] = False\n",
    "plt.rcParams['axes.spines.bottom'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['figure.figsize'] = fig_size\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "plt.rcParams['xtick.top'] = False\n",
    "plt.rcParams['xtick.bottom'] = False\n",
    "plt.rcParams['xtick.color'] = 'white'\n",
    "plt.rcParams['ytick.left'] = False\n",
    "plt.rcParams['ytick.right'] = False\n",
    "plt.rcParams['ytick.color'] = 'white'\n",
    "%matplotlib inline\n",
    "\n",
    "# widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# visdom\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"big\"><b>Intro to PyTorch</span>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<h2 style=\"line-height: 1.4em; font-size: 1.7em;\">MIE Deep Learning Bootcamp, Berlin 2018</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/pytorch_front.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/pytorch_users.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/pytorch_google.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor computation on GPU\n",
    "# Deep learning and automatic differentiation\n",
    "# Optimizers, data loading utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/pytorch_pkg.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch as a fast calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "d = 3000\n",
    "\n",
    "# compute Z = X Y\n",
    "X = np.random.rand(d, d).astype(np.float32)\n",
    "Y = np.random.rand(d, d).astype(np.float32)\n",
    "Z = X.dot(Y)\n",
    "\n",
    "# time\n",
    "%timeit -n1 -r10 Z = X.dot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "d = 3000\n",
    "\n",
    "# compute Z = X Y\n",
    "X = torch.rand(d, d).type(torch.FloatTensor)\n",
    "Y = torch.rand(d, d).type(torch.FloatTensor)\n",
    "Z = torch.mm(X, Y)\n",
    "\n",
    "# time\n",
    "%timeit -n1 -r10 Z = torch.mm(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "d = 3000\n",
    "\n",
    "# static graph\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "Z = tf.matmul(X, Y)\n",
    "\n",
    "# values to feed\n",
    "X_np = np.random.rand(d, d).astype(np.float32)\n",
    "Y_np = np.random.rand(d, d).astype(np.float32)\n",
    "\n",
    "# create session and feed values\n",
    "with tf.Session() as sess:\n",
    "    sess.run(Z, feed_dict={X: X_np, Y: Y_np})\n",
    "    \n",
    "    # time\n",
    "    %timeit -n1 -r10 sess.run(Z, feed_dict={X: X_np, Y: Y_np})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "d = 3000\n",
    "\n",
    "# compute Z = X Y\n",
    "X = torch.rand(d, d).type(torch.FloatTensor)\n",
    "Y = torch.rand(d, d).type(torch.FloatTensor)\n",
    "Z = torch.mm(X, Y)\n",
    "\n",
    "# time\n",
    "%timeit -n1 -r10 Z = torch.mm(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "d = 3000\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "X = torch.rand(d, d).type(dtype)\n",
    "Y = torch.rand(d, d).type(dtype)\n",
    "Z = torch.mm(X, Y)\n",
    "\n",
    "%timeit -n1 -r10 Z = torch.mm(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/ref_mm.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mm(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/ref_matmul.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "a = np.zeros(10000000)\n",
    "b = a * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "a = np.zeros(10000000)\n",
    "a *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "a = torch.zeros(10000000)\n",
    "b = a * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "a = torch.zeros(10000000)\n",
    "a.mul_(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class='big'>PyTorch for automatic differentiation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(1, 6)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1, 6)\n",
    "\n",
    "# Task: compute d(||x||^2)/dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(\\mathbf{x}) = ||\\mathbf{x}||^2 = \\mathbf{x}^T\\mathbf{x}$$\n",
    "\n",
    "here: $$1^2 + 2^2 + 3^2 + 4^2 + 5^2 = 55$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A PyTorch Variable is a wrapper around a PyTorch Tensor, and represents a node in a computational graph. <span class='highlight'>If x is a Variable then x.data is a Tensor giving its value, and x.grad is another Variable holding the gradient of x with respect to some scalar value.</span>\n",
    "> \n",
    "> PyTorch Variables have the same API as PyTorch tensors: (almost) any operation you can do on a Tensor you can also do on a Variable; the difference is that autograd allows you to automatically compute gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: compute d(||x||^2)/dx\n",
    "\n",
    "#x = torch.arange(1, 6)\n",
    "x = Variable(torch.arange(1, 6), requires_grad=True)\n",
    "\n",
    "x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: compute d(||x||^2)/dx\n",
    "\n",
    "x = Variable(torch.arange(1, 6), requires_grad=True)\n",
    "\n",
    "f = x.dot(x)\n",
    "\n",
    "f.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(\\mathbf{x}) = ||\\mathbf{x}||^2 = \\mathbf{x}^T\\mathbf{x}$$\n",
    "\n",
    "here: $$1^2 + 2^2 + 3^2 + 4^2 + 5^2 = 55$$\n",
    "\n",
    "derivative of $f(\\mathbf{x})$ wrt to $\\mathbf{x}$:\n",
    "\n",
    "$$[2 x_1, 2 x_2, 2 x_3, 2 x_4, 2 x_5]$$\n",
    "\n",
    "here: $$[ 2, 4, 6, 8, 10 ]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: compute d(||x||^2)/dx\n",
    "\n",
    "x = Variable(torch.arange(1, 6), requires_grad=True)\n",
    "\n",
    "f = x.dot(x)\n",
    "\n",
    "f.backward()\n",
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/eyes.jpg)\n",
    "\n",
    "http://www.npr.org/sections/health-shots/2015/08/07/430149677/eye-shapes-of-the-animal-world-hint-at-differences-in-our-lifestyles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import imread\n",
    "\n",
    "eyes = imread('img/eyes.jpg', mode='RGB')\n",
    "eye_img = eyes[:425, :425, :]  # width, height, depth\n",
    "plt.imshow(eye_img);\n",
    "\n",
    "img_width, img_height, img_depth = eye_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_np = eye_img  # W x H x C\n",
    "input_img_np = np.swapaxes(input_img_np, 0, 2)  # C x H x W\n",
    "input_img_np = input_img_np.reshape(1, img_depth, img_height, img_width)\n",
    "\n",
    "print(input_img_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "#dtype = torch.cuda.FloatTensor\n",
    "\n",
    "input_img = torch.from_numpy(input_img_np).type(dtype)\n",
    "\n",
    "input_img = Variable(input_img)\n",
    "\n",
    "print(input_img.size())  # B x C x H x W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D convolution\n",
    "\n",
    "![](img/no_padding_no_strides.gif)\n",
    "\n",
    "Dumoulin & Visin, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_np = np.array([[-1,  0,  1],\n",
    "                      [ 0,  0,  0],\n",
    "                      [ 1,  0, -1]])\n",
    "kernel_np = np.asarray((kernel_np, \n",
    "                     kernel_np, \n",
    "                     kernel_np))\n",
    "kernel_np = kernel_np[np.newaxis, :, :, :]  # K, C, H, W\n",
    "\n",
    "print(kernel_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.from_numpy(kernel_np).type(dtype)\n",
    "kernel = Variable(kernel)\n",
    "\n",
    "print(kernel.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_edge = torch.nn.functional.conv2d(input_img, \n",
    "                                       kernel, \n",
    "                                       stride=1)\n",
    "\n",
    "print(conv_edge.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conv_edge.data.numpy().T  # B, C, H, W  ->  W, H, C, B\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(eye_img.shape)\n",
    "plt.imshow(eye_img);\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(result.shape[:3])\n",
    "plt.imshow(result.squeeze());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(in_channels=3, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  stride=1, \n",
    "                  padding=0, \n",
    "                  bias=False)\n",
    "\n",
    "plt.imshow(conv1(input_img).data.numpy().T.squeeze());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/def_init.png)\n",
    "\n",
    "https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/conv.py#L40,L47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(conv1, \n",
    "                    #nn.ReLU()\n",
    "                   )\n",
    "\n",
    "plt.imshow(net(input_img).data.numpy().T.squeeze());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-7, momentum=0.9)\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred = net(input_img)\n",
    "\n",
    "    loss = criterion(pred, conv_edge)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(net(input_img).data.numpy().T.squeeze());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kernel : {}'.format(kernel))\n",
    "\n",
    "print('Learned : {}'.format(next(net.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visdom\n",
    "\n",
    "![](img/visdom_anim.gif?rnd={np.random.rand(})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start server:\n",
    "\n",
    "```bash\n",
    "python -m visdom.server -port 9000\n",
    "```\n",
    "\n",
    "Then open:\n",
    "\n",
    "http://localhost:9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom(port=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vline = vis.line(X=np.linspace(-10., 10., 300),\n",
    "                 Y=np.random.randn(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.reset_parameters()\n",
    "\n",
    "batch = 0\n",
    "vline = vis.line(X=np.empty((1)), Y=np.empty((1)))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-7, momentum=0.9)\n",
    "\n",
    "for b in tqdm(range(10000)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred = net(input_img)\n",
    "\n",
    "    loss = criterion(pred, conv_edge)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    batch += 1\n",
    "    vis.updateTrace(X=np.asarray([batch]), \n",
    "                    Y=np.asarray([loss.data[0]]), \n",
    "                    win=vline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ref_mnist.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
