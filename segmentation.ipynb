{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used for training the network can be downloaded at:\n",
    "\n",
    "http://www.isi.uu.nl/Research/Databases/DRIVE/download.php\n",
    "\n",
    "Extract the data into the folder `datasets/DRIVE_SRC/` such that `test` and `training` (inside the archive) become subfolders of `datasets/DRIVE_SRC/`. Then run the script `datasets/drive/prepare.py` (creates hdf5 files).\n",
    "\n",
    "To step through this notebook, you will need to install a number of packages. First off all, we will need PyTorch, please follow the installation instructions provided at http://pytorch.org/.\n",
    "\n",
    "After successfully doing so, install the following additional packages:\n",
    "- `visdom` : package for visualisations\n",
    "- `tqdm` : package to display progress bars\n",
    "- `ipywidgets` : Jupyter notebook widgets\n",
    "\n",
    "(Use `conda` or `pip` / `pip3` depending on your local setup.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can skip execution of the next cell. \n",
    "\n",
    "(Executing the next cell enables presentation mode (navigate with arrow keys in cell mode); to get out of presentation mode, clear all cell output -- the menu becomes visible on hover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" href=\"css/jupyter.css\">\n",
    "<link rel=\"stylesheet\" href=\"css/presenter.css\">\n",
    "<link rel=\"stylesheet\" href=\"css/cells.css\">\n",
    "<link rel=\"stylesheet\" href=\"css/codemirror.css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# progress bars\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# in case GPUs are used, limit to single device\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor  # Uncomment this to run on GPU\n",
    "\n",
    "# matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "fig_size = (7, 7)\n",
    "plt.rcParams['axes.spines.left'] = False\n",
    "plt.rcParams['axes.spines.bottom'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['figure.figsize'] = fig_size\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "plt.rcParams['xtick.top'] = False\n",
    "plt.rcParams['xtick.bottom'] = False\n",
    "plt.rcParams['xtick.color'] = 'white'\n",
    "plt.rcParams['ytick.left'] = False\n",
    "plt.rcParams['ytick.right'] = False\n",
    "plt.rcParams['ytick.color'] = 'white'\n",
    "%matplotlib inline\n",
    "\n",
    "# widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# visdom\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"big\"><b>UNet in PyTorch</span>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<h2 style=\"line-height: 1.4em; font-size: 1.7em;\">MIE Deep Learning Bootcamp, Berlin 2018</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class='big'>Goal: UNet architecture</span>\n",
    "\n",
    "![](img/u-net-architecture.png)\n",
    "\n",
    "Ronneberger et al., 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRIVE database\n",
    "\n",
    "![](img/task_new.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drive database\n",
    "\n",
    "http://www.isi.uu.nl/Research/Databases/DRIVE/download.php\n",
    "\n",
    "![](img/drive.png?3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.drive.extract_patches import get_data_training, get_data_testing\n",
    "\n",
    "img_size = 64\n",
    "\n",
    "patches_imgs, patches_masks = get_data_training(N=2000, img_size=img_size)\n",
    "dataset_train = [(img, mask) for img, mask in zip(patches_imgs, patches_masks)]\n",
    "\n",
    "test_imgs, test_masks = get_data_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp(i):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(patches_imgs[i,:,:,:].T)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(patches_masks[i,:,:,:].squeeze().T)\n",
    "    plt.show()\n",
    "    \n",
    "interact(disp, i=(0, len(patches_imgs)-1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp(i):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(test_imgs[i,:,:,:].T)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(test_masks[i,:,:,:].squeeze().T)\n",
    "    plt.show()\n",
    "    \n",
    "interact(disp, i=(0, len(test_imgs)-1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def batch_generator(dataset, batch_size=5):\n",
    "    shuffle(dataset)\n",
    "    N_full_batches = len(dataset) // batch_size\n",
    "    for i in range(N_full_batches):\n",
    "        idx_from = batch_size * i\n",
    "        idx_to = batch_size * (i + 1)\n",
    "        imgs, masks = zip(*[(img, mask) for img, mask in dataset[idx_from:idx_to]])\n",
    "        yield imgs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgen = batch_generator(dataset_train, batch_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, masks = next(bgen)\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class='big'>Unet architecture</span>\n",
    "\n",
    "![](img/u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class UnetConv(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels, out_channels, \n",
    "                 kernel=3, stride=1, padding=1,\n",
    "                 act=nn.ReLU()):\n",
    "        super(UnetConv, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, \n",
    "                              kernel, stride, padding)\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.act = act\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv(inputs)\n",
    "        outputs = self.norm(outputs)\n",
    "        if self.act is not None:\n",
    "            return self.act(outputs)\n",
    "        else:\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetDown(nn.Module):\n",
    "    def __init__(self, kernel=2):\n",
    "        super(UnetDown, self).__init__()\n",
    "        self.down = nn.MaxPool2d(kernel)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.down(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetUp(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels, out_channels, \n",
    "                 kernel=2, stride=2, padding=(0, 0, 0, 0)):\n",
    "        super(UnetUp, self).__init__()\n",
    "        \n",
    "        self.padding = padding\n",
    "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, \n",
    "                                         kernel, stride, padding=0)\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        outputs = F.pad(inputs, self.padding)\n",
    "        outputs = self.deconv(outputs)\n",
    "        outputs = self.norm(outputs)\n",
    "        return self.act(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class='big'>Unet architecture</span>\n",
    "\n",
    "![](img/u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetConc(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(UnetConc, self).__init__()\n",
    "\n",
    "        if dropout is not False and dropout > 0.:\n",
    "            self.dropout = torch.nn.Dropout()\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        \n",
    "    def forward(self, inputs1, inputs2):\n",
    "        x = torch.cat([inputs1, inputs2], 1)\n",
    "        \n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        \n",
    "        self.conv1 = UnetConv(3, 32)\n",
    "        self.conv2 = UnetConv(32, 32)\n",
    "        self.conv3 = UnetConv(32, 32)\n",
    "        self.conv4 = UnetConv(32, 32)\n",
    "        self.conv5 = UnetConv(32, 32)\n",
    "        self.conv6 = UnetConv(32, 32)\n",
    "        self.conv7 = UnetConv(32, 32)\n",
    "        self.conv8 = UnetConv(64, 32)\n",
    "        self.conv9 = UnetConv(32, 32)\n",
    "        self.conv10 = UnetConv(64, 32)\n",
    "        self.conv11 = UnetConv(32, 32)\n",
    "        self.conv12 = UnetConv(64, 32)\n",
    "        self.conv13 = UnetConv(32, 32)\n",
    "        self.conv14 = UnetConv(64, 32)\n",
    "        self.conv15 = UnetConv(32, 32)\n",
    "        self.conv16 = UnetConv(32, 1, act=None)\n",
    "    \n",
    "        self.down = UnetDown()\n",
    "\n",
    "        self.up1 = UnetUp(32, 32)\n",
    "        self.up2 = UnetUp(32, 32)\n",
    "        self.up3 = UnetUp(32, 32)\n",
    "        self.up4 = UnetUp(32, 32)\n",
    "        self.up5 = UnetUp(32, 32)\n",
    "        \n",
    "        self.conc = UnetConc()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        \n",
    "        down1 = self.down(conv1)\n",
    "        conv2 = self.conv2(down1)\n",
    "\n",
    "        down2 = self.down(conv2)\n",
    "        conv3 = self.conv3(down2)\n",
    "        \n",
    "        down3 = self.down(conv3)\n",
    "        conv4 = self.conv4(down3)\n",
    "\n",
    "        down4 = self.down(conv4)\n",
    "        conv5 = self.conv5(down4)\n",
    "\n",
    "        down5 = self.down(conv5)\n",
    "        conv6 = self.conv6(down5)\n",
    "        \n",
    "        up1 = self.up1(conv6)\n",
    "        conv7 = self.conv6(up1)\n",
    "        conc1 = self.conc(conv7, down4)\n",
    "        conv8 = self.conv8(conc1)\n",
    "\n",
    "        up2 = self.up2(conv8)\n",
    "        conv9 = self.conv9(up2)\n",
    "        conc2 = self.conc(conv9, down3)\n",
    "        conv10 = self.conv10(conc2)\n",
    "            \n",
    "        up3 = self.up3(conv10)\n",
    "        conv11 = self.conv11(up3)\n",
    "        conc3 = self.conc(conv11, down2)\n",
    "        conv12 = self.conv12(conc3)\n",
    "\n",
    "        up4 = self.up4(conv12)\n",
    "        conv13 = self.conv13(up4)\n",
    "        conc4 = self.conc(conv13, down1)\n",
    "        conv14 = self.conv14(conc4)\n",
    "\n",
    "        up5 = self.up5(conv14)\n",
    "        conv15 = self.conv15(up5)\n",
    "        conv16 = self.conv16(conv15)\n",
    "\n",
    "        outputs = nn.Sigmoid()(conv16)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net = Unet()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Variable(torch.rand(1, 3, 64, 64))\n",
    "net(inputs).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bash\n",
    "# python -m visdom.server -port 9000\n",
    "\n",
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom(port=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "else:\n",
    "    print('CUDA not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.01, \n",
    "                       betas=(0.9, 0.995), eps=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 50\n",
    "\n",
    "iteration = 0\n",
    "vline = vis.line(X=np.asarray([-1, -1]),\n",
    "                 Y=np.asarray([np.nan, np.nan]))\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)): \n",
    "    bgen = batch_generator(dataset_train, batch_size)\n",
    "    \n",
    "    for idx, (imgs, masks) in enumerate(bgen):\n",
    "        \n",
    "        imgs = np.asarray(imgs).reshape(batch_size, 3, img_size, img_size)\n",
    "        masks = np.asarray(masks).reshape(batch_size, 1, img_size, img_size)\n",
    "\n",
    "        inputs = Variable(torch.from_numpy(imgs).type(dtype))\n",
    "        targets = Variable(torch.from_numpy(masks).type(dtype))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = net(inputs)\n",
    "\n",
    "        loss = criterion(pred, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        iteration += 1\n",
    "        current_loss = np.asarray([loss.data[0]])\n",
    "        \n",
    "        vis.updateTrace(X=np.asarray([iteration]), \n",
    "                        Y=current_loss, \n",
    "                        win=vline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('weights/32_epochs_state.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(Variable(torch.from_numpy(test_imgs[:3,:,:,:]).type(dtype)))\n",
    "pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pred.data.numpy()\n",
    "\n",
    "def disp(i):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(outputs[i,:,:,:,].T.squeeze());\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(test_masks[i,:,:,:].T.squeeze());\n",
    "    plt.show()\n",
    "    \n",
    "interact(disp, i=(0, len(outputs)-1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
